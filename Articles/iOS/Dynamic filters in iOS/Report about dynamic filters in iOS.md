Довольно часто в мобильных приложениях встречается фича – запись видео. В
предыдущей статье мы разобрались, что записать видео не так уж и сложно в iOS.
Но это просто запись видео. А что если этого мало? Что если можно сделать что-то
более поразительное? Например записать видео черно-белым или с сепией, как в
старых фильмах. Или добавить любой другой фильтр. Это кажется еще более сложным
и даже невероятным. С одной стороны так и есть. Но если разобраться с тем, как
это работает, как все устроено, то становится куда проще.

Начнем с рассмотрения видео файла. Уже известно, что он состоит их аудиопотока и
видеопотока. Остановимся на видео. Видеопоток состоит из набора картинок,
которые с некоторой частотой меняются на экране. Это кадры или фреймы. В свою
очередь картинка состоит из пикселей, квадратов заполненных одним цветом.
Манипулируя цветом каждого пикселя, мы можем создавать различные эффекты.
Например, заменить цвет пикселя на серый с подобным оттенком и мы получим
картинку состоящую из серых пикселей с разными оттенками. Так получится
черно-белое изображение. Если проделать такое с всеми фреймами видеопотока – мы
получим черно-белый видеоролик. Но в видео много кадров, а в них много пикселей,
что приводит к большому количеству вычислений и большому количеству времени,
необходимому на это.

Есть два возможных подхода к обработке видео. Первый, записать видео, а затем
кадр за кадром обрабатывать его. В таком случае вы не можете во время сьемки
видеть конечный результат на экране. И вам придется подождать, пока видео
обработается. Но есть второй способ, можно накладывать эффекты на видео сразу во
время сьемки.

Для этого мы будем использовать OpenGL и GPU. GPU – это видеокарта. OpenGL –
язык, с помощью которого можно задавать алгоритмы работы с видеокартой. Если
сравнить GPU и CPU, центральный процессор нашего устройстка, то разница между
ними в том, что CPU рассчитан на выполнение немногих параллельных процессов с
разнообразными по сложности задачами, тогда как GPU рассчитан на выполнение
огромного количества параллельных, несложных и однообразных задач. Как это
работает? Мы пишем небольшой алгоритм обработки пикселя. Это будет
программа-шейдера. В видеокарту загружается картинка и шейдер. И процессор
видеокарты попиксельно обрабатывает картинку, применяя для каждого пикселя, не
зависимо от остальных, алгоритм шейдера. В таком случае за одну единицу времени
обрабатывается значительная часть картинки. В случае CPU мы бы отрабатывали не
больше нескольких пикселей одновременно.

![](<report_2_imape_1.png>)

![](<report_2_image_2.png>)

К счастью, нет необходимости тесной работы с видеокартой и писать код шейдеров,
это уже реализовано в открытой библиотеке GPUImage (ссылочка на GitHub
<https://github.com/BradLarson/GPUImage> ). Мы просто добавляем эту библиотеку в
наш проект и используем ее для записи и обработки видео.

Как она работает? Для начала рассмотрим принцип записи видео в iOS.

Можно использовать AVCaptureSession и AVCaptureMovieFileOutput, тогда мы не
получим доступ к процессу записи, а получим готовый видеофайл. Но можно вместо
AVCaptureMovieFileOutput использовать другой AVCaptureOuput класс, который
называется AVCaptureVideoDataOutput. Он дает возможность в коде получать
уведомления о новом полученном буфере. Название метода, в котором мы получаем
так называемые CMSampleBufferRef.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

CMSampleBufferRef – это и есть, по сути, новый фрейм видео, который мы получаем
с камеры и в последствии записываем в видеофайл. Получая, таким образом, доступ
к видеоинформации непосредственно во время записи, мы можем, перед тем как
записать его в файл, внести в него изменения. Этот буфер преобразовывается в
текстуру, которая загружается на GPU и там обрабатывается, с использованием
нужного нам шейдера. На выходе мы получаем новую текстуру с изображением, на
которое наложили эффект, и эту текстуру преобразовываем в новый буфер, который
уже записывается в файл. GPUImage не останавливается на этом, а позволяет
текстуру обрабатывать несколько раз, накладываю поочередно более одного фильтра.

![](<report_2_image_3.png>)

Рассмотрим работу с GPUImage и динамическими фильтров. Код написан на языке
Swift.

Вся логика по работе с GPUImage сосредоточена в классе FRSGPUImageWrapper. В
конструкторе класса настраиваем работу с камерой.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
init(previewView:GPUImageView, orientation:UIInterfaceOrientation) {
	super.init()
	self.previewView = previewView
	self.videoCamera = GPUImageVideoCamera(sessionPreset: AVCaptureSessionPreset1280x720, cameraPosition: .Back)
	self.videoCamera.outputImageOrientation = orientation
	self.videoCamera.startCameraCapture()
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Добавляем фильтер или заменяем старый на новый.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
private func updateFilter(filter:GPUImageFilter?) {
	self.videoCamera.removeAllTargets()
	if (self.filtersGroup != nil) {
		self.filtersGroup.removeAllTargets()
		self.filtersGroup = nil
	}
	if (filter == nil) {
		self.videoCamera.addTarget(self.previewView)
		return
	}
	self.filtersGroup = GPUImageFilterGroup()
	self.filtersGroup.addFilter(filter!)
	self.filtersGroup.initialFilters = [filter!]
	self.filtersGroup.terminalFilter = filter!
	self.filtersGroup.addTarget(self.previewView)
	self.videoCamera.addTarget(self.filtersGroup)
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Например создаем фильтер для черно-белого видео.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
func filterForType(filterType:FRSFilter) -> GPUImageFilter? {
	switch (filterType) {

		…

		case .Grayscale:
		return GPUImageGrayscaleFilter()

		…

		default:
			break
	}
	return nil

}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

После всех необходимых настроек начинаем запись видео.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
func startRecord() {
	self.isRecorded = true
	let url: NSURL? = FRSFileManager().urlForVideo()
	FRSFileManager().removeFile(self.currentVideoURL)
	self.currentVideoURL = url
	self.movieWriter = GPUImageMovieWriter(movieURL: url, size: CGSizeMake(1200, 720))
	self.videoCamera.audioEncodingTarget = self.movieWriter
	if (self.filtersGroup != nil) {
		self.filtersGroup.addTarget(self.movieWriter)
	} else {
		self.videoCamera.addTarget(self.movieWriter)

	}
	self.movieWriter.startRecording()
	self.startRecordTimer()
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

В итоге мы можем легко и быстро добавить в наш проект запись видео с наложением
множества различных видеоэффектов. Ознакомится с проектом FiltersRecordSample
можно перейдя по ссылке на GitHub
<https://github.com/iQueSoft/iOSDemo_VideoDynamicFilters> .
